# AX System Benchmarking Configuration

# GEPA Reflection Model
reflection_model: "openai/gpt-4"
reflection_config:
  temperature: 0.7
  max_tokens: 2000

# ACE Context Assembly
ace_config:
  sources:
    - web
    - database
    - knowledge_graph
    - vector_search
  max_context_tokens: 8000
  relevance_threshold: 0.7
  context_assembly_strategy: "automatic"
  
# DSPy Modules
dspy_config:
  provider: "openai"
  default_model: "gpt-4"
  module_composition: "automatic"
  optimization_strategy: "bootstrap_fewshot"
  
# GEPA Optimization
gepa_config:
  evolution_budget: 50
  mutation_rate: 0.3
  population_size: 10
  target_metric: "composite_score"
  convergence_threshold: 0.01
  max_iterations: 20
  
# Benchmark Settings
benchmark_config:
  validation_split: 0.1
  test_split: 0.1
  random_seed: 42
  max_samples_per_domain: 1000
  
# Evaluation Metrics
metrics:
  accuracy:
    - exact_match
    - field_level
    - semantic_similarity
    - structural_similarity
  speed:
    - response_time
    - context_assembly_time
    - dspy_execution_time
    - gepa_optimization_time
    - throughput
  cost:
    - token_usage
    - api_call_count
    - cost_per_task
    - cost_per_domain
  reliability:
    - error_rate
    - consistency
    - robustness
    
# Scoring Weights
scoring:
  exact_match_weight: 0.4
  field_level_weight: 0.3
  semantic_weight: 0.2
  structural_weight: 0.1
  
# Continuous Benchmarking
continuous_config:
  interval_seconds: 3600
  performance_degradation_threshold: 0.05
  auto_reoptimize: true
  alert_email: "admin@example.com"
  
# Weights & Biases
wandb_config:
  project: "ax-system-benchmarking"
  entity: "ax-team"
  tags:
    - ax-system
    - dspy
    - gepa
    - ace
    
# API Configuration
api_config:
  openai:
    timeout: 60
    max_retries: 3
  perplexity:
    timeout: 60
    max_retries: 3
  openrouter:
    timeout: 60
    max_retries: 3
    
# Storage
storage_config:
  results_dir: "results"
  optimization_dir: "optimization_runs"
  data_dir: "data"
  cache_dir: ".cache"

