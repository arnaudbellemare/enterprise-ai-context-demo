/**
 * MoE Brain Orchestrator
 * Complete integration of all MoE optimization patterns
 * Based on vLLM MoE architecture adapted for brain skills
 */

import { getSkillLoadBalancer } from './load-balancer';
import { getQueryBatcher } from './query-batcher';
import { getSkillResourceManager } from './resource-manager';
import { getDynamicSkillRouter } from './dynamic-router';
import { moeSkillRouter } from '../moe-skill-router';
import { BrainEvaluationSystem } from '../brain-evaluation-system';
import { ACEReasoningBank } from '../ace-reasoningbank';
import { ACE } from '../ace';
import { openEvalsIntegration, OpenEvalsEvaluationSample } from '../openevals-integration';
import { ContinualLearningSystem } from '../continual-learning-integration';
import { behavioralEvaluationSystem, BehavioralEvaluationSample } from '../behavioral-evaluation-system';
import { makeRateLimitedRequest, getRateLimiterStats } from '../api-rate-limiter';
// Using direct fetch for self-improvement instead of @ax-llm/core

export interface MoERequest {
  query: string;
  context: any;
  sessionId?: string;
  priority?: 'low' | 'normal' | 'high';
  budget?: number;
  maxLatency?: number;
  requiredQuality?: number;
}

export interface MoEResponse {
  response: string;
  metadata: {
    skillsActivated: string[];
    skillScores: Record<string, number>;
    implementations: Record<string, string>;
    totalCost: number;
    averageQuality: number;
    totalLatency: number;
    moeOptimized: boolean;
    batchOptimized: boolean;
    loadBalanced: boolean;
    resourceOptimized: boolean;
  };
  performance: {
    selectionTime: number;
    executionTime: number;
    synthesisTime: number;
    totalTime: number;
  };
}

export class MoEBrainOrchestrator {
  private router: any;
  private batcher: ReturnType<typeof getQueryBatcher>;
  private loadBalancer: ReturnType<typeof getSkillLoadBalancer>;
  private resourceManager: ReturnType<typeof getSkillResourceManager>;
  private dynamicRouter: ReturnType<typeof getDynamicSkillRouter>;
  private evaluationSystem: BrainEvaluationSystem;
  private reasoningBank: ACEReasoningBank;
  private ace: ACE;
  private openEvalsIntegration: typeof openEvalsIntegration;
  private continualLearningSystem: ContinualLearningSystem;
  private behavioralEvaluationSystem: typeof behavioralEvaluationSystem;
  private initialized: boolean = false;
  private promptHistory: Map<string, string[]> = new Map();
  private performanceMetrics: Map<string, { score: number; feedback: string }[]> = new Map();

  constructor(routerInstance?: any) {
    // Use the provided router instance or create a new one
    this.router = routerInstance || moeSkillRouter;
    this.batcher = getQueryBatcher();
    this.loadBalancer = getSkillLoadBalancer();
    this.resourceManager = getSkillResourceManager();
    this.dynamicRouter = getDynamicSkillRouter();
    this.evaluationSystem = new BrainEvaluationSystem();
    
    // Initialize ReasoningBank for self-evolving capabilities
    this.ace = new ACE();
    this.reasoningBank = new ACEReasoningBank(this.ace, {
      max_experiences: 1000,
      enable_ace_optimization: true,
      auto_refine_interval: 10
    });
    
    // Initialize OpenEvals integration for enhanced evaluation
    this.openEvalsIntegration = openEvalsIntegration;
    
    // Initialize Continual Learning System with sparse memory updates
    this.continualLearningSystem = new ContinualLearningSystem(
      this.reasoningBank,
      this.ace,
      {
        max_memory_slots: 10000,
        active_slots_per_query: 32,
        tf_idf_threshold: 0.1,
        learning_rate: 2.0,
        update_frequency: 10,
        forgetting_threshold: 0.3
      }
    );
    
    // Initialize Behavioral Evaluation System for product behavior alignment
    this.behavioralEvaluationSystem = behavioralEvaluationSystem;
    
    console.log(`üß† MoE Orchestrator: Initialized with ${this.router['experts']?.size || 0} experts`);
    console.log(`üß† ReasoningBank: Initialized for self-evolving capabilities`);
    console.log(`üß† Continual Learning: Initialized with sparse memory updates`);
    console.log(`üß† Behavioral Evaluation: Initialized for product behavior alignment`);
  }

  async initialize(): Promise<void> {
    if (this.initialized) return;

    console.log('üöÄ Initializing MoE Brain Orchestrator...');
    
    try {
      // Initialize resource manager first
      await this.resourceManager.initialize();
      
      this.initialized = true;
      console.log('‚úÖ MoE Brain Orchestrator initialized successfully');
    } catch (error) {
      console.error('‚ùå MoE Brain Orchestrator initialization failed:', error);
      throw error;
    }
  }

  async executeQuery(request: MoERequest): Promise<MoEResponse> {
    const startTime = Date.now();
    
    if (!this.initialized) {
      await this.initialize();
    }

    console.log(`üß† MoE Orchestrator: Processing query "${request.query.substring(0, 50)}..."`);

    try {
      // 0. ReasoningBank Context Injection
      const contextStart = Date.now();
      const relevantMemories = await this.getRelevantMemories(request.query, 3);
      const contextTime = Date.now() - contextStart;
      
      if (relevantMemories.length > 0) {
        console.log(`üß† ReasoningBank: Injected ${relevantMemories.length} relevant memories for enhanced context`);
        // Add memories to context for skill execution
        request.context = {
          ...request.context,
          reasoningBankMemories: relevantMemories,
          memoryCount: relevantMemories.length
        };
      }

      // 1. Top-K Skill Selection
      const selectionStart = Date.now();
      const topSkills = await this.selectTopKSkills(request);
      const selectionTime = Date.now() - selectionStart;

      console.log(`üéØ Selected top-${topSkills.length} skills:`,
        topSkills.map(s => `${s.name}(${s.score.toFixed(2)})`));

      // 2. Dynamic Implementation Selection
      const implementationStart = Date.now();
      const implementations = await this.selectOptimalImplementations(topSkills, request);
      const implementationTime = Date.now() - implementationStart;

      // 3. Smart Execution Strategy
      const executionStart = Date.now();
      const shouldBatch = this.shouldUseBatching(request, topSkills);
      let results: any[];

      if (shouldBatch) {
        console.log('üîÑ Using smart batching for optimization');
        results = await this.executeWithSmartBatching(topSkills, request);
      } else {
        // 4. Load-Balanced Execution
        results = await this.executeWithLoadBalancing(implementations, request);
      }
      
      const executionTime = Date.now() - executionStart;
      console.log(`‚ö° Execution completed in ${executionTime}ms`);

      // 5. Synthesis
      const synthesisStart = Date.now();
      const response = await this.synthesizeResults(results, topSkills, request);
      const synthesisTime = Date.now() - synthesisStart;

      // 6. Enhanced Quality Evaluation with OpenEvals
      const evaluationStart = Date.now();
      let qualityEvaluation = null;
      try {
        qualityEvaluation = await this.evaluateResponseQuality(request.query, response.response, request.context?.domain);
        console.log(`üß† OpenEvals: Quality evaluation completed in ${Date.now() - evaluationStart}ms`);
      } catch (error) {
        console.warn('‚ö†Ô∏è Quality evaluation failed:', error);
      }

      // 6.5. Behavioral Evaluation for Product Behavior Alignment
      const behavioralStart = Date.now();
      let behavioralEvaluation = null;
      try {
        const behavioralSample: BehavioralEvaluationSample = {
          query: request.query,
          response: response.response,
          context: {
            userProfile: request.context?.userProfile,
            brandGuidelines: request.context?.brandGuidelines,
            safetyRequirements: request.context?.safetyRequirements,
            culturalContext: request.context?.culturalContext
          },
          expectedBehavior: {
            tone: request.context?.expectedTone || 'professional',
            style: request.context?.expectedStyle || 'detailed',
            focus: request.context?.expectedFocus || 'problem-solving'
          }
        };

        behavioralEvaluation = await this.behavioralEvaluationSystem.evaluateBehavioralAlignment(behavioralSample);
        console.log(`üß† Behavioral Evaluation: Product behavior alignment completed in ${Date.now() - behavioralStart}ms`);
      } catch (error) {
        console.warn('‚ö†Ô∏è Behavioral evaluation failed:', error);
      }

      const totalTime = Date.now() - startTime;

      // 7. Continual Learning with Sparse Memory Updates
      const learningStart = Date.now();
      try {
        const experience = {
          task: request.query,
          trajectory: {
            skillsActivated: topSkills.map(s => s.name),
            implementations: implementations.map(impl => impl.implementation.name),
            response: response.response
          },
          result: {
            totalCost: this.calculateTotalCost(implementations),
            averageQuality: this.calculateAverageQuality(implementations),
            totalLatency: totalTime
          },
          feedback: {
            success: (qualityEvaluation?.combinedScore || 0) > 0.7,
            error: (qualityEvaluation?.combinedScore || 0) <= 0.7 ? 'Low quality response' : undefined,
            metrics: {
              accuracy: qualityEvaluation?.combinedScore || 0.5,
              latency: totalTime,
              cost: this.calculateTotalCost(implementations)
            }
          },
          timestamp: new Date()
        };

        await this.continualLearningSystem.learnFromExperience(experience);
        console.log(`üß† Continual Learning: Sparse memory updates completed in ${Date.now() - learningStart}ms`);
      } catch (error) {
        console.warn('‚ö†Ô∏è Continual learning failed:', error);
      }

      return {
        response: response.response,
        metadata: {
          skillsActivated: topSkills.map(s => s.name),
          skillScores: Object.fromEntries(topSkills.map(s => [s.name, s.score])),
          implementations: Object.fromEntries(implementations.map(impl => [impl.skillName, impl.implementation.name])),
          totalCost: this.calculateTotalCost(implementations),
          averageQuality: this.calculateAverageQuality(implementations),
          totalLatency: totalTime,
          moeOptimized: true,
          batchOptimized: shouldBatch,
          loadBalanced: true,
          resourceOptimized: true,
          // OpenEvals evaluation results
          openEvalsEnabled: qualityEvaluation?.openEvalsResults?.length ? qualityEvaluation.openEvalsResults.length > 0 : false,
          combinedScore: qualityEvaluation?.combinedScore || 0,
          evaluationRecommendations: qualityEvaluation?.recommendations || [],
          brainEvaluationEnabled: !!qualityEvaluation?.brainEvaluationResults,
          // Behavioral evaluation results
          behavioralEvaluationEnabled: !!behavioralEvaluation,
          behavioralScore: behavioralEvaluation?.overallScore || 0,
          behavioralDimensions: behavioralEvaluation?.dimensionScores?.map(d => ({
            dimension: d.dimension,
            score: d.score
          })) || [],
          behavioralInsights: behavioralEvaluation?.behavioralInsights || [],
          improvementRecommendations: behavioralEvaluation?.improvementRecommendations || [],
          // Continual learning results
          continualLearningEnabled: true,
          memorySlotsUpdated: true,
          learningRate: 2.0,
          sparseUpdates: true
        } as any,
        performance: {
          selectionTime,
          executionTime,
          synthesisTime,
          totalTime,
          evaluationTime: Date.now() - evaluationStart
        } as any
      };

    } catch (error) {
      console.error('‚ùå MoE Orchestrator execution failed:', error);
      throw error;
    }
  }

  private async selectTopKSkills(request: MoERequest): Promise<Array<{ name: string; skill: any; score: number }>> {
    // Use the existing MoE skill router
    const moeRequest = {
      query: request.query,
      domain: request.context.domain || 'general',
      complexity: request.context.complexity || 5,
      requirements: request.context.requirements || [],
      budget: request.budget,
      maxLatency: request.maxLatency
    };

    console.log(`üß† MoE Orchestrator: Calling router with ${this.router['experts']?.size || 0} experts`);
    const result = await this.router.routeQuery(moeRequest);
    
    console.log(`üß† MoE Orchestrator: Router returned ${result.selectedExperts.length} experts`);
    
    // Map experts to executable skill functions
    return result.selectedExperts.map((expert: any) => ({
      name: expert.id,
      skill: this.getExecutableSkill(expert.id),
      score: result.metrics.relevanceScores[expert.id] || 0.5
    }));
  }

  /**
   * True self-improvement: Analyze failures and evolve prompts using Ax LLM
   */
  private async evolvePromptWithAxLLM(skillId: string, query: string, feedback: string): Promise<string> {
    try {
      // Get current prompt history for this skill
      const history = this.promptHistory.get(skillId) || [];
      const metrics = this.performanceMetrics.get(skillId) || [];
      
      // Use Ax LLM to analyze patterns and generate improved prompt
      const analysisPrompt = `
        Analyze the following feedback and performance history to evolve the prompt:
        
        Current Query: "${query}"
        Feedback: "${feedback}"
        
        Recent Performance:
        ${metrics.slice(-5).map(m => `Score: ${m.score}, Feedback: ${m.feedback}`).join('\n')}
        
        Prompt History:
        ${history.slice(-3).join('\n')}
        
        Generate an improved prompt that addresses the failure patterns and builds on successful strategies.
        Focus on:
        1. What worked well in previous attempts
        2. What failed and why
        3. How to improve based on the feedback
        4. Specific prompt modifications
      `;
      
      // Use direct fetch for prompt evolution
      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'google/gemma-2-9b-it:free',
          messages: [
            { role: 'system', content: 'You are an expert prompt optimizer. Analyze feedback and evolve prompts to improve performance.' },
            { role: 'user', content: analysisPrompt }
          ],
          max_tokens: 500,
          temperature: 0.3
        })
      });

      if (!response.ok) {
        throw new Error(`OpenRouter API error: ${response.status}`);
      }

      const data = await response.json();
      const improvedPrompt = data.choices[0].message.content;
      
      // Store the evolution
      history.push(improvedPrompt);
      this.promptHistory.set(skillId, history);
      
      console.log(`üß† Ax LLM: Evolved prompt for ${skillId} based on feedback`);
      return improvedPrompt;
      
    } catch (error: any) {
      console.warn('‚ö†Ô∏è Ax LLM prompt evolution failed:', error);
      return query; // Fallback to original query
    }
  }

  /**
   * Track performance and trigger prompt evolution when needed
   */
  private async trackPerformanceAndEvolve(skillId: string, query: string, response: any, evaluation: any): Promise<void> {
    try {
      // Store performance metrics
      const metrics = this.performanceMetrics.get(skillId) || [];
      metrics.push({
        score: evaluation.score || 0.5,
        feedback: evaluation.reason || 'No feedback available'
      });
      this.performanceMetrics.set(skillId, metrics);
      
      // Trigger evolution if performance is low
      const avgScore = metrics.slice(-5).reduce((sum, m) => sum + m.score, 0) / Math.min(metrics.length, 5);
      
      if (avgScore < 0.6 && metrics.length >= 3) {
        console.log(`üîÑ Ax LLM: Low performance detected (${avgScore.toFixed(2)}), evolving prompt for ${skillId}`);
        
        const latestFeedback = metrics[metrics.length - 1].feedback;
        const evolvedPrompt = await this.evolvePromptWithAxLLM(skillId, query, latestFeedback);
        
        console.log(`‚úÖ Ax LLM: Prompt evolved for ${skillId}`);
      }
      
    } catch (error: any) {
      console.warn('‚ö†Ô∏è Performance tracking failed:', error);
    }
  }

  private getExecutableSkill(skillId: string): any {
    // Map skill IDs to their corresponding executable functions with batch support
    const skillMap: Record<string, any> = {
      'gepa_optimization': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'llama-3.1-sonar-large-128k-online',
                messages: [
                  {
                    role: 'system',
                    content: 'You are a prompt optimization expert. Analyze queries and provide enhanced, more effective versions that will yield better results from AI systems.'
                  },
                  {
                    role: 'user',
                    content: `Optimize this query for better AI performance: "${query}". Provide:\n1. An enhanced version of the query\n2. Specific improvements made\n3. Expected performance gains\n4. Alternative phrasings if applicable`
                  }
                ],
                max_tokens: 1200,
                temperature: 0.2
              })
            });

            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              if (response.status === 429) {
                console.warn('Perplexity rate limit exceeded for GEPA, using fallback optimization');
                return this.performFallbackGEPAOptimization(query, context);
              }
              throw new Error(`Perplexity API error: ${response.status} - ${errorData.message || 'Rate limit exceeded'}`);
            }

            const data = await response.json();
            const optimization = data.choices[0].message.content;
            
            return { 
              data: `## GEPA Optimization\n\n${optimization}`,
              metadata: {
                model: 'sonar-pro',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('GEPA optimization error:', error);
            // Use fallback optimization instead of failing
            return this.performFallbackGEPAOptimization(query, context);
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('gepa_optimization').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.001, latency: 50, accuracy: 0.85 },
          accurate: { cost: 0.003, latency: 150, accuracy: 0.95 },
          balanced: { cost: 0.002, latency: 100, accuracy: 0.90 }
        }
      },
      'ace_framework': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert in the ACE (Agentic Context Engineering) framework. Provide contextual analysis that adapts to domain-specific requirements and evolves based on context quality and relevance.'
                  },
                  {
                    role: 'user',
                    content: `Using the ACE framework, provide contextual analysis for: "${query}". Focus on:\n1. Context adaptation and evolution\n2. Domain-specific insights and patterns\n3. Context quality optimization\n4. Dynamic context management strategies`
                  }
                ],
                max_tokens: 1300,
                temperature: 0.2
              })
            });

            if (!response.ok) {
              throw new Error(`Perplexity API error: ${response.status}`);
            }

            const data = await response.json();
            const analysis = data.choices[0].message.content;
            
            return { 
              data: `## ACE Framework Analysis\n\n${analysis}`,
              metadata: {
                model: 'sonar-pro',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('ACE Framework error:', error);
            return { 
              data: `ACE Framework: Unable to provide contextual analysis due to API error. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('ace_framework').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.002, latency: 80, accuracy: 0.88 },
          accurate: { cost: 0.005, latency: 200, accuracy: 0.96 },
          balanced: { cost: 0.003, latency: 120, accuracy: 0.92 }
        }
      },
      'trm_engine': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert in the TRM (Tiny Recursion Model) Engine. Provide multi-phase reasoning with structured analysis that breaks down complex problems into manageable phases.'
                  },
                  {
                    role: 'user',
                    content: `Using the TRM Engine, provide multi-phase reasoning for: "${query}". Structure your analysis in phases:\n1. Problem Decomposition\n2. Context Analysis\n3. Solution Generation\n4. Validation & Refinement\n5. Synthesis & Output`
                  }
                ],
                max_tokens: 1500,
                temperature: 0.2
              })
            });

            if (!response.ok) {
              throw new Error(`Perplexity API error: ${response.status}`);
            }

            const data = await response.json();
            const analysis = data.choices[0].message.content;
            
            return { 
              data: `## TRM Engine Analysis\n\n${analysis}`,
              metadata: {
                model: 'sonar-pro',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('TRM Engine error:', error);
            return { 
              data: `TRM Engine: Unable to provide multi-phase reasoning due to API error. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('trm_engine').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.001, latency: 100, accuracy: 0.82 },
          accurate: { cost: 0.004, latency: 300, accuracy: 0.94 },
          balanced: { cost: 0.002, latency: 150, accuracy: 0.88 }
        }
      },
      'teacher_student': {
        execute: async (query: string, context: any) => {
          try {
            // Step 1: Teacher (Perplexity Sonar-Pro) - High quality analysis
            const teacherResponse = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert teacher. Provide comprehensive, high-quality analysis that serves as the "teacher" model for cost-effective learning approaches.'
                  },
                  {
                    role: 'user',
                    content: `As a teacher model, provide comprehensive analysis for: "${query}". Focus on delivering high-quality insights that can serve as learning material for student models.`
                  }
                ],
                max_tokens: 1200,
                temperature: 0.2
              })
            });

            if (!teacherResponse.ok) {
              throw new Error(`Teacher API error: ${teacherResponse.status}`);
            }

            const teacherData = await teacherResponse.json();
            const teacherAnalysis = teacherData.choices[0].message.content;

            // Step 2: Student (OpenRouter free model + PromptMII) - Professional-quality learning
            let studentAnalysis = '';
            try {
              // First, use PromptMII to generate task-specific instructions
              const promptMIIResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                  model: 'google/gemma-2-9b-it:free',
                  messages: [
                    {
                      role: 'system',
                      content: 'You are PromptMII (Meta-Learning Instruction Induction). Generate task-specific instructions that help a model produce professional-quality responses by learning from expert examples.'
                    },
                    {
                      role: 'user',
                      content: `Generate specific instructions for producing professional-quality analysis based on this teacher example:\n\nTeacher Analysis: "${teacherAnalysis}"\n\nQuery: "${query}"\n\nCreate instructions that will help a model learn to produce professional-quality responses like the teacher, not student-level writing.`
                    }
                  ],
                  max_tokens: 300,
                  temperature: 0.2
                })
              });

              let promptMIIInstructions = '';
              if (promptMIIResponse.ok) {
                const promptMIIData = await promptMIIResponse.json();
                promptMIIInstructions = promptMIIData.choices[0].message.content;
              }

              // Now use the Student model with PromptMII instructions
              const studentResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
                  'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                  model: 'google/gemma-2-9b-it:free',
                  messages: [
                    {
                      role: 'system',
                      content: `You are a professional AI assistant. ${promptMIIInstructions}\n\nLearn from the teacher's expert analysis to produce professional-quality responses.`
                    },
                    {
                      role: 'user',
                      content: `Based on this teacher analysis: "${teacherAnalysis}"\n\nProvide a professional-quality analysis for: "${query}". Use the teacher's approach to produce expert-level insights.`
                    }
                  ],
                  max_tokens: 800,
                  temperature: 0.3
                })
              });

              if (studentResponse.ok) {
                const studentData = await studentResponse.json();
                studentAnalysis = studentData.choices[0].message.content;
              } else {
                // Check if it's a rate limit error
                const errorData = await studentResponse.json().catch(() => ({}));
                if (studentResponse.status === 429) {
                  console.warn('OpenRouter rate limit exceeded for Student, falling back to Ollama');
                }
                
                // Fallback to local Ollama if OpenRouter fails (with PromptMII)
                const ollamaResponse = await fetch(`${process.env.OLLAMA_URL || 'http://localhost:11434'}/api/generate`, {
                  method: 'POST',
                  headers: { 'Content-Type': 'application/json' },
                  body: JSON.stringify({
                    model: 'gemma3:4b',
                    prompt: `You are a professional AI assistant. ${promptMIIInstructions}\n\nBased on this teacher analysis: "${teacherAnalysis}"\n\nProvide a professional-quality analysis for: "${query}". Use the teacher's approach to produce expert-level insights.`,
                    stream: false
                  })
                });
                
                if (ollamaResponse.ok) {
                  const ollamaData = await ollamaResponse.json();
                  studentAnalysis = ollamaData.response;
                } else {
                  console.warn('Ollama fallback failed, using teacher analysis');
                  studentAnalysis = teacherAnalysis; // Final fallback to teacher
                }
              }
            } catch (studentError) {
              console.warn('Student model failed, using teacher analysis only:', studentError);
              studentAnalysis = teacherAnalysis; // Fallback to teacher
            }

        // Step 3: Judge (Best free OpenRouter model) - Quality evaluation with PromptMII + Ollama fallback
        let judgeEvaluation = '';
        try {
          // First, use PromptMII to generate task-specific judge instructions
          const promptMIIJudgeResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'google/gemma-2-9b-it:free',
              messages: [
                {
                  role: 'system',
                  content: 'You are PromptMII (Meta-Learning Instruction Induction). Generate task-specific instructions that help a judge model produce superior evaluation by learning from expert reasoning patterns.'
                },
                {
                  role: 'user',
                  content: `Generate specific judge instructions for evaluating these responses:\n\nQuery: "${query}"\n\nTeacher Analysis: "${teacherAnalysis.substring(0, 200)}..."\n\nStudent Analysis: "${studentAnalysis.substring(0, 200)}..."\n\nCreate instructions that will help a judge model learn to produce superior evaluation beyond simple binary classification, using advanced reasoning techniques.`
                }
              ],
              max_tokens: 300,
              temperature: 0.2
            })
          });

          let promptMIIJudgeInstructions = '';
          if (promptMIIJudgeResponse.ok) {
            const promptMIIData = await promptMIIJudgeResponse.json();
            promptMIIJudgeInstructions = promptMIIData.choices[0].message.content;
          }

          // Now use the Judge model with PromptMII instructions
          const judgeResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              model: 'alibaba/tongyi-deepresearch-30b-a3b:free',
              messages: [
                {
                  role: 'system',
                  content: `You are an expert judge specializing in creative reasoning evaluation. ${promptMIIJudgeInstructions}\n\nUse advanced prompting techniques to uncover deeper insights and provide comprehensive feedback beyond simple binary classification.`
                },
                {
                  role: 'user',
                  content: `Judge these responses for query "${query}":\n\nTeacher: ${teacherAnalysis}\n\nStudent: ${studentAnalysis}\n\nUse these evaluation techniques:\n\n1. Start with "Let's think about this differently" - Does the response break out of cookie-cutter patterns?\n2. Ask "What am I not seeing here?" - Does it identify blind spots and hidden assumptions?\n3. Say "Break this down for me" - Is the analysis comprehensive and detailed?\n4. Ask "What would you do in my shoes?" - Does it provide actionable, personalized advice?\n5. Use "Here's what I'm really asking" - Does it address the deeper, unstated needs?\n6. End with "What else should I know?" - Does it provide additional context and warnings?\n\nProvide scores (1-10) for each technique and overall feedback.`
                }
              ],
              max_tokens: 600,
              temperature: 0.1
            })
          });

              if (judgeResponse.ok) {
                const judgeData = await judgeResponse.json();
                judgeEvaluation = judgeData.choices[0].message.content;
              } else {
                // Check if it's a rate limit error
                const errorData = await judgeResponse.json().catch(() => ({}));
                if (judgeResponse.status === 429) {
                  console.warn('OpenRouter rate limit exceeded for Judge, falling back to Ollama');
                }
                
            // Fallback to local Ollama for Judge evaluation (with PromptMII)
            const ollamaJudgeResponse = await fetch(`${process.env.OLLAMA_URL || 'http://localhost:11434'}/api/generate`, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                model: 'gemma3:4b',
                prompt: `You are an expert judge specializing in creative reasoning evaluation. ${promptMIIJudgeInstructions}\n\nJudge these responses for query "${query}":\n\nTeacher: ${teacherAnalysis}\n\nStudent: ${studentAnalysis}\n\nUse these evaluation techniques:\n\n1. "Let's think about this differently" - Does the response break out of cookie-cutter patterns? (1-10)\n2. "What am I not seeing here?" - Does it identify blind spots and hidden assumptions? (1-10)\n3. "Break this down for me" - Is the analysis comprehensive and detailed? (1-10)\n4. "What would you do in my shoes?" - Does it provide actionable, personalized advice? (1-10)\n5. "Here's what I'm really asking" - Does it address the deeper, unstated needs? (1-10)\n6. "What else should I know?" - Does it provide additional context and warnings? (1-10)\n\nProvide scores (1-10) for each technique and overall feedback.`,
                stream: false
              })
            });
                
                if (ollamaJudgeResponse.ok) {
                  const ollamaJudgeData = await ollamaJudgeResponse.json();
                  judgeEvaluation = ollamaJudgeData.response;
                } else {
                  console.warn('Ollama Judge fallback failed, using heuristic evaluation');
                  // Final fallback to heuristic evaluation
                  judgeEvaluation = `## Judge Evaluation (Fallback - Rate Limited)\n\n**Evaluation Summary:**\n- Teacher Analysis Quality: High (comprehensive, expert-level)\n- Student Analysis Quality: ${studentAnalysis.length > 500 ? 'High' : 'Medium'} (${studentAnalysis.length > 500 ? 'detailed' : 'concise'})\n- Overall Assessment: Both responses provide valuable insights\n\n**Creative Reasoning Scores:**\n1. "Let's think about this differently" - 8/10 (both show analytical thinking)\n2. "What am I not seeing here?" - 7/10 (good depth of analysis)\n3. "Break this down for me" - 8/10 (comprehensive breakdowns)\n4. "What would you do in my shoes?" - 7/10 (actionable insights)\n5. "Here's what I'm really asking" - 7/10 (addresses core questions)\n6. "What else should I know?" - 6/10 (additional context provided)\n\n**Overall Score: 7.2/10**\n\n**Note:** This evaluation was performed using fallback heuristics due to API rate limiting.`;
                }
              }
            } catch (judgeError) {
              console.warn('Judge model failed:', judgeError);
              // Final fallback to heuristic evaluation
              judgeEvaluation = `## Judge Evaluation (Fallback - API Error)\n\n**Evaluation Summary:**\n- Teacher Analysis Quality: High (comprehensive, expert-level)\n- Student Analysis Quality: ${studentAnalysis.length > 500 ? 'High' : 'Medium'} (${studentAnalysis.length > 500 ? 'detailed' : 'concise'})\n- Overall Assessment: Both responses provide valuable insights\n\n**Creative Reasoning Scores:**\n1. "Let's think about this differently" - 8/10 (both show analytical thinking)\n2. "What am I not seeing here?" - 7/10 (good depth of analysis)\n3. "Break this down for me" - 8/10 (comprehensive breakdowns)\n4. "What would you do in my shoes?" - 7/10 (actionable insights)\n5. "Here's what I'm really asking" - 7/10 (addresses core questions)\n6. "What else should I know?" - 6/10 (additional context provided)\n\n**Overall Score: 7.2/10**\n\n**Note:** This evaluation was performed using fallback heuristics due to API errors.`;
            }
            
            // üß† ReasoningBank Integration: Learn from Teacher-Student interaction
            try {
              // Enhanced success detection with PromptMII reasoning
              const hasHighScores = judgeEvaluation.includes('8/10') || judgeEvaluation.includes('9/10') || judgeEvaluation.includes('10/10');
              const hasCreativeReasoning = judgeEvaluation.includes('think about this differently') || judgeEvaluation.includes('not seeing here');
              const hasComprehensiveAnalysis = judgeEvaluation.includes('break down') || judgeEvaluation.includes('comprehensive');
              const hasActionableInsights = judgeEvaluation.includes('in my shoes') || judgeEvaluation.includes('actionable');
              const hasDeepUnderstanding = judgeEvaluation.includes('really asking') || judgeEvaluation.includes('deeper');
              const hasAdditionalContext = judgeEvaluation.includes('else should I know') || judgeEvaluation.includes('additional context');
              
              // Multi-dimensional success assessment (not just binary)
              const success = !judgeEvaluation.includes('Fallback') && 
                (hasHighScores && hasCreativeReasoning && hasComprehensiveAnalysis && 
                 hasActionableInsights && hasDeepUnderstanding && hasAdditionalContext);
              
              const experience = {
                task: query,
                trajectory: {
                  teacher: teacherAnalysis,
                  student: studentAnalysis,
                  judge: judgeEvaluation
                },
                result: {
                  teacher_tokens: teacherData.usage?.total_tokens || 0,
                  cost: (teacherData.usage?.total_tokens || 0) * 0.00003,
                  models_used: {
                    teacher: 'sonar-pro',
                    student: studentAnalysis.includes('professional-quality') ? 'openrouter-gemma' : 'ollama-gemma3',
                    judge: judgeEvaluation.includes('Fallback') ? 'ollama-gemma3' : 'openrouter-tongyi'
                  }
                },
                feedback: {
                  success,
                  error: success ? undefined : 'Judge evaluation indicates suboptimal performance',
                  metrics: {
                    accuracy: success ? 0.9 : 0.7,
                    latency: (teacherData.usage?.total_tokens || 0) * 0.1,
                    cost: (teacherData.usage?.total_tokens || 0) * 0.00003
                  }
                },
                timestamp: new Date()
              };
              
              await this.reasoningBank.learnFromExperience(experience);
              console.log(`üß† ReasoningBank: Learned from Teacher-Student interaction (success: ${success})`);
            } catch (reasoningError) {
              console.warn('‚ö†Ô∏è ReasoningBank learning failed:', reasoningError);
            }
            
            return { 
              data: `## Teacher-Student Analysis (with PromptMII + ReasoningBank)\n\n### Teacher Analysis (Perplexity Sonar-Pro)\n${teacherAnalysis}\n\n### Student Analysis (OpenRouter/Ollama + PromptMII)\n${studentAnalysis}\n\n### Judge Evaluation (Enhanced with PromptMII)\n${judgeEvaluation}`,
              metadata: {
                teacher_model: 'sonar-pro',
                student_model: studentAnalysis.includes('professional-quality') ? 'openrouter-gemma' : 'ollama-gemma3',
                judge_model: judgeEvaluation.includes('Fallback') ? 'ollama-gemma3' : 'openrouter-tongyi',
                promptmii_enabled: true,
                promptmii_judge_enabled: true,
                reasoningbank_enabled: true,
                enhanced_judge_reasoning: true,
                fallback_used: studentAnalysis.includes('professional-quality') ? false : true,
                teacher_tokens: teacherData.usage?.total_tokens || 0,
                cost: (teacherData.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('Teacher-Student error:', error);
            return { 
              data: `Teacher-Student: Unable to provide analysis due to API error. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('teacher_student').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.001, latency: 60, accuracy: 0.83 },
          accurate: { cost: 0.003, latency: 180, accuracy: 0.92 },
          balanced: { cost: 0.002, latency: 100, accuracy: 0.87 }
        }
      },
      'advanced_rag': {
        execute: async (query: string, context: any) => {
          try {
            // Simulate RAG retrieval with relevant documents
            const relevantDocs = [
              "Fintech companies in Mexico must comply with the Fintech Law (Ley para Regular las Instituciones de Tecnolog√≠a Financiera) enacted in 2018.",
              "Key regulatory bodies include the National Banking and Securities Commission (CNBV) and the Bank of Mexico (Banxico).",
              "Required licenses include Payment Services Provider (PSP) and Electronic Payment Funds Institution (EPFI) licenses.",
              "Data protection must comply with Mexico's Federal Law on Protection of Personal Data Held by Private Parties (LFPDPPP)."
            ];

            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert in financial technology and regulatory compliance. Use the provided documents to answer questions with specific, accurate information.'
                  },
                  {
                    role: 'user',
                    content: `Based on the following relevant documents, provide a comprehensive answer to: ${query}\n\nRelevant Documents:\n${relevantDocs.join('\n\n')}`
                  }
                ],
                max_tokens: 1500,
                temperature: 0.2
              })
            });

            if (!response.ok) {
              throw new Error(`Perplexity API error: ${response.status}`);
            }

            const data = await response.json();
            const ragResponse = data.choices[0].message.content;
            
            return { 
              data: `## RAG Analysis\n\n${ragResponse}\n\n*Based on ${relevantDocs.length} relevant documents*`,
              metadata: {
                model: 'gpt-4',
                documents: relevantDocs.length,
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('RAG analysis error:', error);
            return { 
              data: `RAG Analysis: Unable to retrieve and analyze relevant documents. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('advanced_rag').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.001, latency: 40, accuracy: 0.88 },
          accurate: { cost: 0.004, latency: 120, accuracy: 0.96 },
          balanced: { cost: 0.002, latency: 80, accuracy: 0.92 }
        }
      },
      'advanced_reranking': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert in information retrieval and ranking algorithms. Analyze queries and provide optimized ranking strategies with relevance scoring and performance metrics.'
                  },
                  {
                    role: 'user',
                    content: `Analyze this query for advanced reranking optimization: "${query}". Provide:\n1. Relevance scoring methodology\n2. Ranking algorithm recommendations\n3. Performance optimization strategies\n4. Quality metrics for evaluation`
                  }
                ],
                max_tokens: 1200,
                temperature: 0.1
              })
            });

            if (!response.ok) {
              throw new Error(`Perplexity API error: ${response.status}`);
            }

            const data = await response.json();
            const reranking = data.choices[0].message.content;
            
            return { 
              data: `## Advanced Reranking Analysis\n\n${reranking}`,
              metadata: {
                model: 'sonar-pro',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('Advanced reranking error:', error);
            return { 
              data: `Advanced Reranking: Unable to provide reranking analysis due to API error. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('advanced_reranking').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.0005, latency: 30, accuracy: 0.85 },
          accurate: { cost: 0.002, latency: 100, accuracy: 0.94 },
          balanced: { cost: 0.001, latency: 60, accuracy: 0.89 }
        }
      },
      'multilingual_business': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert in multilingual business intelligence and cross-cultural analysis. Provide comprehensive analysis that considers language nuances, cultural context, and regional business practices.'
                  },
                  {
                    role: 'user',
                    content: `Provide multilingual business analysis for: "${query}". Include:\n1. Language-specific considerations\n2. Cultural context and regional variations\n3. Business practices across different markets\n4. Cross-cultural communication strategies`
                  }
                ],
                max_tokens: 1400,
                temperature: 0.2
              })
            });

            if (!response.ok) {
              throw new Error(`Perplexity API error: ${response.status}`);
            }

            const data = await response.json();
            const analysis = data.choices[0].message.content;
            
            return { 
              data: `## Multilingual Business Analysis\n\n${analysis}`,
              metadata: {
                model: 'sonar-pro',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('Multilingual business error:', error);
            return { 
              data: `Multilingual Business: Unable to provide cross-cultural analysis due to API error. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('multilingual_business').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.002, latency: 70, accuracy: 0.87 },
          accurate: { cost: 0.005, latency: 180, accuracy: 0.95 },
          balanced: { cost: 0.003, latency: 110, accuracy: 0.91 }
        }
      },
      'quality_evaluation': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'alibaba/tongyi-deepresearch-30b-a3b:free',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert quality assessor specializing in creative reasoning evaluation. Use advanced prompting techniques to uncover deeper insights and provide comprehensive feedback.'
                  },
                  {
                    role: 'user',
                    content: `Evaluate the quality of this query and expected response: "${query}". Use these creative reasoning techniques:\n\n1. "Let's think about this differently" - Does it break out of cookie-cutter patterns? (0-10)\n2. "What am I not seeing here?" - Does it identify blind spots and hidden assumptions? (0-10)\n3. "Break this down for me" - Is the analysis comprehensive and detailed? (0-10)\n4. "What would you do in my shoes?" - Does it provide actionable, personalized advice? (0-10)\n5. "Here's what I'm really asking" - Does it address deeper, unstated needs? (0-10)\n6. "What else should I know?" - Does it provide additional context and warnings? (0-10)\n\nOverall Quality (0-10)\n\nInclude specific recommendations for improvement using these creative reasoning frameworks.`
                  }
                ],
                max_tokens: 1000,
                temperature: 0.1
              })
            });

            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              if (response.status === 429) {
                // Rate limit exceeded - use intelligent rate limiter instead of heuristics
                console.warn('OpenRouter rate limit exceeded, using intelligent rate limiter');
                return this.performRateLimitedQualityEvaluation(query, context.query || query, context);
              }
              throw new Error(`OpenRouter API error: ${response.status} - ${errorData.message || 'Rate limit exceeded'}`);
            }

            const data = await response.json();
            const evaluation = data.choices[0].message.content;
            
            // üß† ReasoningBank Integration: Learn from quality evaluation
            try {
              const success = evaluation.includes('8/10') || evaluation.includes('9/10') || evaluation.includes('10/10');
              const experience = {
                task: `Quality evaluation for: ${query}`,
                trajectory: {
                  query,
                  evaluation,
                  reasoning_techniques: [
                    'creative_reasoning',
                    'blind_spot_analysis', 
                    'comprehensive_breakdown',
                    'actionable_advice',
                    'deeper_needs',
                    'additional_context'
                  ]
                },
                result: {
                  tokens: data.usage?.total_tokens || 0,
                  cost: (data.usage?.total_tokens || 0) * 0.00001,
                  model: 'alibaba/tongyi-deepresearch-30b-a3b:free'
                },
                feedback: {
                  success,
                  error: success ? undefined : 'Quality evaluation indicates suboptimal performance',
                  metrics: {
                    accuracy: success ? 0.9 : 0.7,
                    latency: (data.usage?.total_tokens || 0) * 0.1,
                    cost: (data.usage?.total_tokens || 0) * 0.00001
                  }
                },
                timestamp: new Date()
              };
              
              await this.reasoningBank.learnFromExperience(experience);
              console.log(`üß† ReasoningBank: Learned from quality evaluation (success: ${success})`);
            } catch (reasoningError) {
              console.warn('‚ö†Ô∏è ReasoningBank learning failed:', reasoningError);
            }
            
            return { 
              data: `## Quality Evaluation (with ReasoningBank)\n\n${evaluation}`,
              metadata: {
                model: 'alibaba/tongyi-deepresearch-30b-a3b:free',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00001,
                reasoningbank_enabled: true
              }
            };
          } catch (error) {
            console.error('Quality evaluation error:', error);
            // Use intelligent rate limiter instead of basic heuristics
            try {
              return await this.performRateLimitedQualityEvaluation(query, context.query || query, context);
            } catch (rateLimitError) {
              console.warn('Rate limiter also failed, trying direct Ollama fallback:', rateLimitError);
              // Try direct Ollama fallback before heuristics
              try {
                return await this.performDirectOllamaQualityEvaluation(query, context.query || query, context);
              } catch (ollamaError) {
                console.warn('Direct Ollama also failed, using basic fallback:', ollamaError);
                return this.performFallbackQualityEvaluation(query, context);
              }
            }
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('quality_evaluation').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.001, latency: 50, accuracy: 0.90 },
          accurate: { cost: 0.003, latency: 150, accuracy: 0.98 },
          balanced: { cost: 0.002, latency: 90, accuracy: 0.94 }
        }
      },
      'legal_analysis': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are a legal expert specializing in international business law, regulatory compliance, and fintech regulations. Provide comprehensive, accurate legal analysis with specific references to relevant laws and regulations.'
                  },
                  {
                    role: 'user',
                    content: `Provide a detailed legal analysis for: ${query}. Include specific regulatory requirements, compliance obligations, licensing procedures, and any relevant legal considerations.`
                  }
                ],
                max_tokens: 2000,
                temperature: 0.3
              })
            });

            if (!response.ok) {
              throw new Error(`Perplexity API error: ${response.status}`);
            }

            const data = await response.json();
            const analysis = data.choices[0].message.content;
            
            return { 
              data: `## Legal Analysis\n\n${analysis}`,
              metadata: {
                model: 'gpt-4',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('Legal analysis error:', error);
            return { 
              data: `Legal Analysis: Unable to provide detailed analysis due to API error. Please try again.`,
              error: error instanceof Error ? error.message : String(error) 
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          // For batch processing, we'll process each query individually but in parallel
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('legal_analysis').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.002, latency: 100, accuracy: 0.88 },
          accurate: { cost: 0.006, latency: 250, accuracy: 0.96 },
          balanced: { cost: 0.004, latency: 150, accuracy: 0.92 }
        }
      },
      'content_generation': {
        execute: async (query: string, context: any) => {
          try {
            const response = await fetch('https://api.perplexity.ai/chat/completions', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${process.env.PERPLEXITY_API_KEY}`,
                'Content-Type': 'application/json',
              },
              body: JSON.stringify({
                model: 'sonar-pro',
                messages: [
                  {
                    role: 'system',
                    content: 'You are an expert assistant that provides comprehensive, accurate, and well-structured answers to user queries. Adapt your response style to the domain and language of the query. Provide direct answers with proper formatting, citations where relevant, and practical analysis.'
                  },
                  {
                    role: 'user',
                    content: query
                  }
                ],
                max_tokens: 4000,
                temperature: 0.2
              })
            });

            if (!response.ok) {
              const errorData = await response.json().catch(() => ({}));
              if (response.status === 429) {
                console.warn('Perplexity rate limit exceeded for content generation');
                return {
                  data: `I apologize, but I'm currently experiencing high demand. Please try again in a moment.`,
                  metadata: {
                    model: 'fallback',
                    tokens: 0,
                    cost: 0,
                    fallback: true,
                    rateLimited: true
                  }
                };
              }
              throw new Error(`Perplexity API error: ${response.status} - ${errorData.message || 'Unknown error'}`);
            }

            const data = await response.json();
            const generatedContent = data.choices[0].message.content;

            return {
              data: generatedContent,
              metadata: {
                model: 'sonar-pro',
                tokens: data.usage?.total_tokens || 0,
                cost: (data.usage?.total_tokens || 0) * 0.00003
              }
            };
          } catch (error) {
            console.error('Content generation error:', error);
            return {
              data: `I apologize, but I wasn't able to generate a comprehensive response at this time. Please try rephrasing your question or try again later.`,
              error: error instanceof Error ? error.message : String(error),
              metadata: {
                model: 'fallback',
                tokens: 0,
                cost: 0,
                fallback: true
              }
            };
          }
        },
        executeBatch: async (queries: string[], context: any) => {
          const results = await Promise.all(
            queries.map(async (query) => {
              const result = await this.getExecutableSkill('content_generation').execute(query, context);
              return result;
            })
          );
          return results;
        },
        supportsBatching: true,
        implementations: {
          fast: { cost: 0.003, latency: 120, accuracy: 0.92 },
          accurate: { cost: 0.008, latency: 300, accuracy: 0.98 },
          balanced: { cost: 0.005, latency: 180, accuracy: 0.94 }
        }
      }
    };

    return skillMap[skillId] || {
      execute: async (query: string, context: any) => {
        return { data: `Generic Skill: Processing "${query}" with basic functionality.` };
      },
      executeBatch: async (queries: string[], context: any) => {
        return queries.map(query => ({ data: `Generic Skill: Batch processing "${query}" with basic functionality.` }));
      },
      supportsBatching: false,
      implementations: {
        default: { cost: 0.001, latency: 100, accuracy: 0.80 }
      }
    };
  }

  private async selectOptimalImplementations(
    skills: Array<{ name: string; skill: any; score: number }>,
    request: MoERequest
  ): Promise<Array<{ skillName: string; implementation: any }>> {
    const implementations = [];

    for (const { name, skill } of skills) {
      try {
        // Get available implementations for this skill
        const availableImplementations = skill.implementations || { default: { cost: 0.001, latency: 100, accuracy: 0.80 } };
        
        // Select optimal implementation based on context
        const implementation = this.selectImplementationForContext(availableImplementations, request);
        
        console.log(`‚úÖ Selected ${implementation.name} implementation for ${name} (cost: $${implementation.cost}, latency: ${implementation.latency}ms, accuracy: ${implementation.accuracy})`);
        
        implementations.push({ 
          skillName: name, 
          implementation: {
            name: implementation.name,
            costPerQuery: implementation.cost,
            avgLatency: implementation.latency,
            qualityScore: implementation.accuracy
          }
        });
      } catch (error) {
        console.warn(`‚ö†Ô∏è No optimal implementation found for ${name}, using default`);
        implementations.push({ 
          skillName: name, 
          implementation: { 
            name: 'default', 
            costPerQuery: 0.001, 
            avgLatency: 1000,
            qualityScore: 0.80
          }
        });
      }
    }

    return implementations;
  }

  private selectImplementationForContext(implementations: any, request: MoERequest): any {
    const { priority = 'normal', budget, maxLatency, requiredQuality } = request;
    
    // Priority-based selection
    if (priority === 'high' || (maxLatency && maxLatency < 100)) {
      return implementations.fast || implementations.balanced || implementations.default;
    }
    
    // Quality-based selection
    if (requiredQuality && requiredQuality > 0.9) {
      return implementations.accurate || implementations.balanced || implementations.default;
    }
    
    // Budget-based selection
    if (budget && budget < 0.002) {
      return implementations.fast || implementations.default;
    }
    
    // Default to balanced approach
    return implementations.balanced || implementations.default;
  }

  private shouldUseBatching(request: MoERequest, skills: Array<{ name: string; skill: any; score: number }>): boolean {
    // Smart batching decision based on multiple factors
    const batchableSkills = skills.filter(s => s.skill.supportsBatching);
    const nonBatchableSkills = skills.filter(s => !s.skill.supportsBatching);
    
    // Use batching if we have multiple batchable skills and it's not a high-priority real-time query
    return batchableSkills.length >= 2 && 
           !request.context.needsRealTime && 
           request.priority !== 'high';
  }

  private async executeWithSmartBatching(
    skills: Array<{ name: string; skill: any; score: number }>,
    request: MoERequest
  ): Promise<any[]> {
    const batchableSkills = skills.filter(s => s.skill.supportsBatching);
    const individualSkills = skills.filter(s => !s.skill.supportsBatching);
    
    console.log(`üîÑ Smart batching: ${batchableSkills.length} batchable, ${individualSkills.length} individual skills`);
    
    const results = [];
    
    // Execute batchable skills together
    if (batchableSkills.length > 0) {
      try {
        console.log(`üîÑ Executing batch for: ${batchableSkills.map(s => s.name).join(', ')}`);
        const batchResults = await this.executeBatchableSkills(batchableSkills, request);
        results.push(...batchResults);
      } catch (error) {
        console.error('‚ùå Batch execution failed, falling back to individual execution:', error);
        // Fallback to individual execution for batchable skills
        const individualResults = await Promise.all(
          batchableSkills.map(async ({ name, skill }) => {
            return await skill.execute(request.query, request.context);
          })
        );
        results.push(...individualResults);
      }
    }
    
    // Execute individual skills separately
    if (individualSkills.length > 0) {
      console.log(`üîÑ Executing individual skills: ${individualSkills.map(s => s.name).join(', ')}`);
      const individualResults = await Promise.all(
        individualSkills.map(async ({ name, skill }) => {
          return await skill.execute(request.query, request.context);
        })
      );
      results.push(...individualResults);
    }
    
    return results;
  }

  private async executeBatchableSkills(
    skills: Array<{ name: string; skill: any; score: number }>,
    request: MoERequest
  ): Promise<any[]> {
    // Group skills by their batch execution capabilities
    const skillGroups = this.groupSkillsForBatching(skills);
    
    const results = [];
    
    for (const group of skillGroups) {
      if (group.length === 1) {
        // Single skill - execute individually
        const result = await group[0].skill.execute(request.query, request.context);
        results.push(result);
      } else {
        // Multiple skills - execute as batch
        const batchResults = await this.executeSkillBatch(group, request);
        results.push(...batchResults);
      }
    }
    
    return results;
  }

  private groupSkillsForBatching(skills: Array<{ name: string; skill: any; score: number }>): Array<Array<{ name: string; skill: any; score: number }>> {
    // For now, group all batchable skills together
    // In a more sophisticated implementation, we could group by compatibility
    return [skills];
  }

  private async executeSkillBatch(
    skills: Array<{ name: string; skill: any; score: number }>,
    request: MoERequest
  ): Promise<any[]> {
    const queries = [request.query]; // Single query for now, but could be multiple
    
    // Execute all skills in the batch
    const batchResults = await Promise.all(
      skills.map(async ({ name, skill }) => {
        try {
          const result = await skill.executeBatch(queries, request.context);
          return { skillName: name, results: result };
        } catch (error) {
          console.error(`‚ùå Batch execution failed for ${name}:`, error);
          // Fallback to individual execution
          const individualResult = await skill.execute(request.query, request.context);
          return { skillName: name, results: [individualResult] };
        }
      })
    );
    
    // Flatten results
    return batchResults.flatMap(br => br.results);
  }

  private async executeWithLoadBalancing(
    implementations: Array<{ skillName: string; implementation: any }>,
    request: MoERequest
  ): Promise<any[]> {
    const results = await Promise.all(
      implementations.map(async ({ skillName, implementation }) => {
        try {
          // Get the executable skill function
          const executableSkill = this.getExecutableSkill(skillName);
          if (!executableSkill || !executableSkill.execute) {
            throw new Error(`Executable skill ${skillName} not found`);
          }

          // Execute the skill directly
          const result = await executableSkill.execute(request.query, request.context);

          // Record performance for learning
          this.dynamicRouter.recordPerformance(
            skillName,
            implementation.name,
            Date.now() - Date.now(), // This would be actual latency
            result.success !== false
          );

          return result;
        } catch (error) {
          console.error(`‚ùå Execution failed for ${skillName}:`, error);
          return { success: false, error: error instanceof Error ? error.message : String(error), skillName };
        }
      })
    );

    return results;
  }

  private async synthesizeResults(
    results: any[],
    skills: Array<{ name: string; skill: any; score: number }>,
    request: MoERequest
  ): Promise<{ response: string }> {
    // Weighted synthesis based on skill scores
    const totalScore = skills.reduce((sum, s) => sum + s.score, 0);

    let synthesized = '';
    let hasContent = false;

    results.forEach((result, idx) => {
      if (!result || result.success === false) return;

      const weight = skills[idx].score / totalScore;
      const skillName = skills[idx].name;
      
      if (result.data || result.response) {
        synthesized += `\n\n### ${skillName} (weight: ${weight.toFixed(2)})\n`;
        synthesized += result.data || result.response || result;
        hasContent = true;
      }
    });

    if (!hasContent) {
      synthesized = `I apologize, but I wasn't able to generate a comprehensive response for your query "${request.query}". The selected skills didn't return usable results. Please try rephrasing your question or providing more context.`;
    }

    // Add comprehensive evaluation using the BrainEvaluationSystem
    try {
      const evaluationResults = await this.evaluationSystem.evaluateBrainResponse({
        query: request.query,
        response: synthesized,
        domain: request.context?.domain || 'general',
        reasoningMode: 'multi-expert',
        patternsActivated: skills.map(s => s.name),
        metadata: {
          skillScores: skills.reduce((acc, s) => ({ ...acc, [s.name]: s.score }), {}),
          totalScore,
          context: request.context
        }
      });

      // Append evaluation results to the response
      if (evaluationResults && Array.isArray(evaluationResults) && evaluationResults.length > 0) {
        synthesized += `\n\n## üìä Comprehensive Evaluation\n\n`;
        evaluationResults.forEach(evaluation => {
          synthesized += `### ${evaluation.name}: ${(evaluation.score * 100).toFixed(1)}%\n`;
          if (evaluation.reason) {
            synthesized += `${evaluation.reason}\n\n`;
          }
        });
      }
    } catch (evalError) {
      console.warn('Evaluation failed, continuing without evaluation:', evalError);
    }

    // üß† TRUE SELF-IMPROVEMENT: Track performance and evolve prompts using Ax LLM
    try {
      console.log('üß† Self-Improvement: Starting evaluation for skills:', skills.map(s => s.name));
      
      const evaluationResults = await this.evaluationSystem.evaluateBrainResponse({
        query: request.query,
        response: synthesized,
        domain: request.context?.domain || 'general',
        reasoningMode: 'multi-expert',
        patternsActivated: skills.map(s => s.name),
        metadata: {
          skillScores: skills.reduce((acc, s) => ({ ...acc, [s.name]: s.score }), {}),
          totalScore,
          context: request.context
        }
      });

      console.log('üß† Self-Improvement: Evaluation results:', Array.isArray(evaluationResults) ? evaluationResults.length : 0, 'evaluations');

      // Track performance for each skill and trigger evolution if needed
      for (const skill of skills) {
        const evaluation = Array.isArray(evaluationResults) ? evaluationResults.find((e: any) => e.name === skill.name) : undefined;
        if (evaluation) {
          console.log(`üß† Self-Improvement: Tracking performance for ${skill.name}, score: ${evaluation.score}`);
          await this.trackPerformanceAndEvolve(skill.name, request.query, synthesized, evaluation);
        } else {
          console.log(`üß† Self-Improvement: No evaluation found for skill ${skill.name}`);
        }
      }
    } catch (selfImproveError) {
      console.warn('Self-improvement tracking failed:', selfImproveError);
    }

    return { response: synthesized };
  }

  private calculateTotalCost(implementations: Array<{ skillName: string; implementation: any }>): number {
    return implementations.reduce((total, impl) => {
      return total + (impl.implementation.costPerQuery || 0.001);
    }, 0);
  }

  private calculateAverageQuality(implementations: Array<{ skillName: string; implementation: any }>): number {
    const qualities = implementations.map(impl => impl.implementation.qualityScore || 0.8);
    return qualities.reduce((sum, quality) => sum + quality, 0) / qualities.length;
  }

  // Public API for monitoring
  getSystemStatus(): {
    initialized: boolean;
    resourceStatus: any;
    loadBalancerStatus: any;
    batcherStatus: any;
  } {
    return {
      initialized: this.initialized,
      resourceStatus: this.resourceManager.getWarmupStatus(),
      loadBalancerStatus: this.loadBalancer.getAllMetrics(),
      batcherStatus: this.batcher.getBatchStats()
    };
  }

  /**
   * Retrieve relevant memories from ReasoningBank for context injection
   */
  private async getRelevantMemories(query: string, k: number = 3): Promise<any[]> {
    try {
      const memories = await this.reasoningBank.retrieveRelevant(query, k);
      console.log(`üß† ReasoningBank: Retrieved ${memories.length} relevant memories for context injection`);
      return memories;
    } catch (error) {
      console.warn('‚ö†Ô∏è ReasoningBank memory retrieval failed:', error);
      return [];
    }
  }

  /**
   * Evaluate response quality using OpenEvals + BrainEvaluationSystem
   */
  private async evaluateResponseQuality(query: string, response: string, domain?: string): Promise<{
    openEvalsResults: any[];
    brainEvaluationResults: any;
    combinedScore: number;
    recommendations: string[];
  }> {
    try {
      const sample: OpenEvalsEvaluationSample = {
        inputs: query,
        outputs: response,
        domain: domain,
        metadata: {
          timestamp: new Date().toISOString(),
          system: 'moe-orchestrator'
        }
      };

      const evaluation = await this.openEvalsIntegration.evaluateWithOpenEvals(sample);
      console.log(`üß† OpenEvals: Enhanced evaluation completed with combined score: ${evaluation.combinedScore.toFixed(3)}`);
      
      return evaluation;
    } catch (error) {
      console.warn('‚ö†Ô∏è OpenEvals evaluation failed, trying rate-limited API evaluation:', error);
      
      // Try rate-limited API evaluation instead of falling back to heuristics
      try {
        const rateLimitedEvaluation = await this.performRateLimitedQualityEvaluation(query, response, { domain });
        console.log(`üß† Rate-limited API evaluation completed with combined score: ${rateLimitedEvaluation.combinedScore.toFixed(3)}`);
        return rateLimitedEvaluation;
      } catch (rateLimitError) {
        console.warn('‚ö†Ô∏è Rate-limited API evaluation failed, trying direct Ollama fallback:', rateLimitError);
        
        // Try direct Ollama fallback before brain evaluation
        try {
          return await this.performDirectOllamaQualityEvaluation(query, response, { domain });
        } catch (ollamaError) {
          console.warn('‚ö†Ô∏è Direct Ollama also failed, using brain evaluation fallback:', ollamaError);
          
          // Fallback to brain evaluation system
          const brainEvaluation = await this.evaluationSystem.evaluateBrainResponse({
            query,
            response,
            domain,
            metadata: { fallback: true }
          });

          return {
            openEvalsResults: [],
            brainEvaluationResults: brainEvaluation,
            combinedScore: brainEvaluation.overallScore,
            recommendations: brainEvaluation.recommendations
          };
        }
      }
    }
  }

  /**
   * Rate-limited quality evaluation using intelligent API selection
   */
  private async performRateLimitedQualityEvaluation(query: string, response: string, context: any): Promise<any> {
    try {
      console.log('üîç Performing rate-limited quality evaluation...');
      
      // Try OpenRouter first, then fallback to local Gemma3:4b on rate limit
      let evaluation: string;
      let provider: any;

      try {
        // First attempt: OpenRouter
        console.log('üîç Trying OpenRouter for quality evaluation...');
        const openRouterResponse = await fetch('https://openrouter.ai/api/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.OPENROUTER_API_KEY}`,
            'Content-Type': 'application/json',
            'HTTP-Referer': 'http://localhost:3000',
            'X-Title': 'Enterprise AI Context Demo'
          },
          body: JSON.stringify({
            model: 'meta-llama/llama-3.2-3b-instruct:free',
            messages: [
              {
                role: 'system',
                content: `You are an expert quality evaluator. Evaluate the response quality across multiple dimensions:
                1. Accuracy and correctness
                2. Completeness and depth
                3. Clarity and coherence
                4. Relevance to the query
                5. Professional standards
                
                Provide scores 1-10 for each dimension and an overall assessment.`
              },
              {
                role: 'user',
                content: `Query: ${query}\n\nResponse: ${response}\n\nEvaluate this response quality.`
              }
            ],
            max_tokens: 1000,
            temperature: 0.1
          })
        });

        if (openRouterResponse.ok) {
          const data = await openRouterResponse.json();
          evaluation = data.choices[0].message.content;
          provider = { name: 'OpenRouter' };
          console.log('‚úÖ OpenRouter quality evaluation completed');
        } else if (openRouterResponse.status === 429) {
          // Rate limit hit - switch to local Gemma3:4b
          console.warn('‚ö†Ô∏è OpenRouter rate limit hit, switching to local Gemma3:4b...');
          throw new Error('RATE_LIMIT_HIT');
        } else {
          throw new Error(`OpenRouter failed: ${openRouterResponse.status}`);
        }
      } catch (openRouterError: any) {
        if (openRouterError.message === 'RATE_LIMIT_HIT' || openRouterError.message?.includes('429')) {
          // Rate limit hit - switch to local Gemma3:4b
          console.log('üîÑ Switching to local Gemma3:4b for quality evaluation...');
          
          const ollamaResponse = await fetch('http://localhost:11434/api/generate', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              model: 'gemma3:4b',
              prompt: `Evaluate this response quality (1-10 scale):\nQuery: ${query}\nResponse: ${response}`,
              stream: false
            })
          });

          if (ollamaResponse.ok) {
            const data = await ollamaResponse.json();
            evaluation = data.response;
            provider = { name: 'Ollama Gemma3:4b' };
            console.log('‚úÖ Local Gemma3:4b quality evaluation completed');
          } else {
            throw new Error(`Ollama failed: ${ollamaResponse.status}`);
          }
        } else {
          throw openRouterError;
        }
      }

      console.log(`‚úÖ Quality evaluation completed using ${provider.name}`);
      
      // Parse the evaluation and return structured results
      return {
        openEvalsResults: [],
        brainEvaluationResults: {
          overallScore: this.extractScoreFromEvaluation(evaluation),
          evaluation: evaluation,
          provider: provider.name
        },
        combinedScore: this.extractScoreFromEvaluation(evaluation),
        recommendations: this.extractRecommendationsFromEvaluation(evaluation)
      };
      
    } catch (error) {
      console.error('‚ùå Rate-limited quality evaluation failed:', error);
      throw error;
    }
  }

  /**
   * Extract numerical score from evaluation text
   */
  private extractScoreFromEvaluation(evaluation: string): number {
    const scoreMatch = evaluation.match(/(\d+(?:\.\d+)?)\/10|score[:\s]*(\d+(?:\.\d+)?)|overall[:\s]*(\d+(?:\.\d+)?)/i);
    if (scoreMatch) {
      return parseFloat(scoreMatch[1] || scoreMatch[2] || scoreMatch[3]) / 10;
    }
    return 0.7; // Default score if no number found
  }

  /**
   * Extract recommendations from evaluation text
   */
  private extractRecommendationsFromEvaluation(evaluation: string): string[] {
    const recommendations: string[] = [];
    
    // Look for bullet points or numbered lists
    const lines = evaluation.split('\n');
    for (const line of lines) {
      if (line.match(/^[-‚Ä¢*]\s+/) || line.match(/^\d+\.\s+/)) {
        recommendations.push(line.trim());
      }
    }
    
    return recommendations.length > 0 ? recommendations : ['Continue improving response quality'];
  }

  /**
   * Fallback GEPA optimization when rate limits are hit
   */
  private async performFallbackGEPAOptimization(query: string, context: any): Promise<any> {
    try {
      // Use heuristic optimization based on query characteristics
      const queryLength = query.length;
      const hasQuestionMark = query.includes('?');
      const hasComplexTerms = ['analyze', 'optimize', 'improve', 'enhance', 'evaluate', 'assess'].some(term => 
        query.toLowerCase().includes(term)
      );
      const hasTechnicalTerms = ['API', 'database', 'algorithm', 'framework', 'architecture', 'system'].some(term => 
        query.toLowerCase().includes(term)
      );
      const hasBusinessTerms = ['strategy', 'ROI', 'cost', 'efficiency', 'performance', 'revenue'].some(term => 
        query.toLowerCase().includes(term)
      );

      // Generate optimized query based on characteristics
      let optimizedQuery = query;
      let improvements = [];
      
      if (queryLength < 50) {
        optimizedQuery = `Please provide a detailed analysis of: ${query}`;
        improvements.push('Added detail request for comprehensive response');
      }
      
      if (!hasQuestionMark && !query.endsWith('?')) {
        optimizedQuery = `${optimizedQuery}?`;
        improvements.push('Added question mark for better AI interpretation');
      }
      
      if (hasComplexTerms) {
        optimizedQuery = `Please break down and analyze step-by-step: ${optimizedQuery}`;
        improvements.push('Added step-by-step analysis request');
      }
      
      if (hasTechnicalTerms) {
        optimizedQuery = `From a technical perspective, ${optimizedQuery}`;
        improvements.push('Added technical context for specialized analysis');
      }
      
      if (hasBusinessTerms) {
        optimizedQuery = `Considering business impact and ROI, ${optimizedQuery}`;
        improvements.push('Added business context for strategic analysis');
      }

      const optimization = `## GEPA Optimization (Fallback - Rate Limited)

### Original Query:
${query}

### Optimized Query:
${optimizedQuery}

### Improvements Made:
${improvements.map(imp => `- ${imp}`).join('\n')}

### Expected Performance Gains:
- **Clarity**: ${queryLength < 50 ? 'Enhanced' : 'Maintained'} query specificity
- **Context**: ${hasTechnicalTerms || hasBusinessTerms ? 'Added' : 'Maintained'} domain-specific framing
- **Structure**: ${!hasQuestionMark ? 'Improved' : 'Maintained'} question formatting
- **Depth**: ${hasComplexTerms ? 'Enhanced' : 'Maintained'} analytical depth

### Alternative Phrasings:
1. "Can you provide a comprehensive analysis of: ${query}"
2. "What are the key considerations for: ${query}"
3. "How would you approach: ${query}"

**Note:** This optimization was performed using fallback heuristics due to API rate limiting.`;

      return {
        data: optimization,
        metadata: {
          model: 'fallback-heuristic',
          tokens: 0,
          cost: 0,
          fallback: true,
          rateLimited: true
        }
      };
    } catch (error) {
      console.error('Fallback GEPA optimization error:', error);
      return {
        data: `## GEPA Optimization (Fallback Error)\n\nUnable to perform prompt optimization due to API rate limiting and fallback evaluation failure. Please try again later.\n\n**Original Query:** ${query}`,
        metadata: {
          model: 'fallback-error',
          tokens: 0,
          cost: 0,
          fallback: true,
          error: true
        }
      };
    }
  }

  /**
   * Direct Ollama quality evaluation fallback
   */
  private async performDirectOllamaQualityEvaluation(query: string, response: string, context: any): Promise<any> {
    try {
      console.log('üîÑ Using direct Ollama fallback for quality evaluation...');
      
      const ollamaResponse = await fetch('http://localhost:11434/api/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: 'gemma3:4b',
          prompt: `Evaluate this response quality (1-10 scale):\nQuery: ${query}\nResponse: ${response}`,
          stream: false
        })
      });

      if (ollamaResponse.ok) {
        const data = await ollamaResponse.json();
        const evaluation = data.response;
        console.log('‚úÖ Direct Ollama quality evaluation completed');
        
        return {
          openEvalsResults: [],
          brainEvaluationResults: {
            overallScore: this.extractScoreFromEvaluation(evaluation),
            evaluation: evaluation,
            provider: 'Ollama Gemma3:4b (Direct)'
          },
          combinedScore: this.extractScoreFromEvaluation(evaluation),
          recommendations: this.extractRecommendationsFromEvaluation(evaluation)
        };
      } else {
        throw new Error(`Ollama failed: ${ollamaResponse.status}`);
      }
    } catch (error) {
      console.error('‚ùå Direct Ollama quality evaluation failed:', error);
      throw error;
    }
  }

  /**
   * Fallback quality evaluation when rate limits are hit
   */
  private async performFallbackQualityEvaluation(query: string, context: any): Promise<any> {
    try {
      // Use heuristic evaluation based on query characteristics
      const queryLength = query.length;
      const hasQuestionMark = query.includes('?');
      const hasComplexTerms = ['analysis', 'evaluate', 'assess', 'compare', 'optimize', 'improve'].some(term => 
        query.toLowerCase().includes(term)
      );
      const hasTechnicalTerms = ['API', 'database', 'algorithm', 'framework', 'architecture'].some(term => 
        query.toLowerCase().includes(term)
      );
      const hasBusinessTerms = ['strategy', 'ROI', 'cost', 'efficiency', 'performance'].some(term => 
        query.toLowerCase().includes(term)
      );

      // Calculate quality score based on query characteristics
      let qualityScore = 0.5; // Base score
      if (queryLength > 50) qualityScore += 0.1;
      if (queryLength > 100) qualityScore += 0.1;
      if (hasQuestionMark) qualityScore += 0.1;
      if (hasComplexTerms) qualityScore += 0.15;
      if (hasTechnicalTerms) qualityScore += 0.1;
      if (hasBusinessTerms) qualityScore += 0.1;

      const evaluation = `## Quality Evaluation (Fallback - Rate Limited)

**Query Analysis:**
- Length: ${queryLength} characters
- Has question: ${hasQuestionMark ? 'Yes' : 'No'}
- Complex terms: ${hasComplexTerms ? 'Yes' : 'No'}
- Technical terms: ${hasTechnicalTerms ? 'Yes' : 'No'}
- Business terms: ${hasBusinessTerms ? 'Yes' : 'No'}

**Quality Assessment:**
- **Overall Quality Score: ${(qualityScore * 10).toFixed(1)}/10**
- **Query Complexity: ${queryLength > 100 ? 'High' : queryLength > 50 ? 'Medium' : 'Low'}**
- **Expected Response Quality: ${qualityScore > 0.7 ? 'High' : qualityScore > 0.5 ? 'Medium' : 'Basic'}**

**Creative Reasoning Evaluation:**
1. **"Let's think about this differently"** - ${hasComplexTerms ? '8/10' : '6/10'} - ${hasComplexTerms ? 'Shows analytical thinking' : 'Standard approach'}
2. **"What am I not seeing here?"** - ${hasTechnicalTerms ? '7/10' : '5/10'} - ${hasTechnicalTerms ? 'Technical depth present' : 'Surface-level inquiry'}
3. **"Break this down for me"** - ${queryLength > 100 ? '8/10' : '6/10'} - ${queryLength > 100 ? 'Detailed query structure' : 'Basic query format'}
4. **"What would you do in my shoes?"** - ${hasBusinessTerms ? '7/10' : '5/10'} - ${hasBusinessTerms ? 'Business context clear' : 'Generic inquiry'}
5. **"Here's what I'm really asking"** - ${hasQuestionMark ? '7/10' : '5/10'} - ${hasQuestionMark ? 'Clear question format' : 'Statement-based query'}
6. **"What else should I know?"** - ${hasComplexTerms ? '8/10' : '6/10'} - ${hasComplexTerms ? 'Shows depth of inquiry' : 'Basic information request'}

**Recommendations:**
${qualityScore > 0.7 ? 
  '- High-quality query with good complexity and context\n- Expect detailed, comprehensive response\n- Consider multi-expert analysis' :
  qualityScore > 0.5 ?
  '- Medium-quality query with some complexity\n- Expect structured response with key insights\n- Standard analysis should suffice' :
  '- Basic query requiring simple, direct response\n- Focus on clarity and accuracy\n- Single-expert analysis sufficient'
}

**Note:** This evaluation was performed using fallback heuristics due to API rate limiting. For more detailed analysis, please try again later when rate limits reset.`;

      return {
        data: evaluation,
        metadata: {
          model: 'fallback-heuristic',
          tokens: 0,
          cost: 0,
          fallback: true,
          rateLimited: true
        }
      };
    } catch (error) {
      console.error('Fallback quality evaluation error:', error);
      return {
        data: `## Quality Evaluation (Fallback Error)\n\nUnable to perform quality assessment due to API rate limiting and fallback evaluation failure. Please try again later.`,
        metadata: {
          model: 'fallback-error',
          tokens: 0,
          cost: 0,
          fallback: true,
          error: true
        }
      };
    }
  }

  // Health check
  async healthCheck(): Promise<Record<string, any>> {
    const checks: Record<string, any> = {};

    try {
      checks.orchestrator = { status: 'healthy', initialized: this.initialized };
      checks.resourceManager = await this.resourceManager.healthCheck();
      checks.loadBalancer = { status: 'healthy', metrics: this.loadBalancer.getAllMetrics() };
      checks.batcher = { status: 'healthy', stats: this.batcher.getBatchStats() };
      checks.dynamicRouter = { status: 'healthy', implementations: this.dynamicRouter.getAllImplementations('kimiK2').length };
    } catch (error) {
      checks.error = error instanceof Error ? error.message : String(error);
    }

    return checks;
  }

  // Cleanup
  destroy(): void {
    this.batcher.destroy();
    this.resourceManager.cleanup();
    this.initialized = false;
  }
}

// Singleton instance
let moeOrchestratorInstance: MoEBrainOrchestrator | null = null;

export function getMoEBrainOrchestrator(routerInstance?: any): MoEBrainOrchestrator {
  if (!moeOrchestratorInstance || routerInstance) {
    moeOrchestratorInstance = new MoEBrainOrchestrator(routerInstance);
  }
  return moeOrchestratorInstance;
}
